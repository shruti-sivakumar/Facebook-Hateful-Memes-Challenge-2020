{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01b26dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import ResNet50_Weights\n",
    "\n",
    "from transformers import DistilBertModel, DistilBertTokenizerFast\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7f3e518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    embedding_dim: int = 512\n",
    "    num_classes: int = 2\n",
    "    batch_size: int = 8\n",
    "    lr: float = 1e-3\n",
    "    epochs: int = 10\n",
    "    max_length: int = 128\n",
    "    subset_size: int = 100\n",
    "    seed: int = 42\n",
    "    num_workers: int = 0  # set >0 if your environment supports it\n",
    "    pin_memory: bool = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d452c693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Project root: /Users/shrutisivakumar/Library/CloudStorage/OneDrive-Personal/College Stuff/Sem 6/Projects/NLP/Facebook-Hateful-Memes-Challenge-2020\n",
      "✓ Image directory: /Users/shrutisivakumar/Library/CloudStorage/OneDrive-Personal/College Stuff/Sem 6/Projects/NLP/Facebook-Hateful-Memes-Challenge-2020/data/original/img\n",
      "✓ Found 10000 images\n",
      "✓ Train file: /Users/shrutisivakumar/Library/CloudStorage/OneDrive-Personal/College Stuff/Sem 6/Projects/NLP/Facebook-Hateful-Memes-Challenge-2020/data/original/train.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "notebook_dir = Path.cwd()\n",
    "project_root = notebook_dir.parent if notebook_dir.name == \"src\" else notebook_dir\n",
    "\n",
    "data_dir = project_root / \"data\"\n",
    "original_dir = data_dir / \"original\"\n",
    "processed_dir = data_dir / \"processed\"\n",
    "img_dir = original_dir / \"img\"\n",
    "models_dir = project_root / \"models\"\n",
    "results_dir = project_root / \"results\"\n",
    "\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "results_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_jsonl = original_dir / \"train.jsonl\"\n",
    "\n",
    "if not img_dir.exists():\n",
    "    raise FileNotFoundError(f\"Image directory not found: {img_dir}\")\n",
    "if not train_jsonl.exists():\n",
    "    raise FileNotFoundError(f\"Train file not found: {train_jsonl}\")\n",
    "\n",
    "print(f\"✓ Project root: {project_root}\")\n",
    "print(f\"✓ Image directory: {img_dir}\")\n",
    "print(f\"✓ Found {len(list(img_dir.glob('*.png')))} images\")\n",
    "print(f\"✓ Train file: {train_jsonl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f67581c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class HatefulMemesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      - image tensor: [3, 224, 224]\n",
    "      - raw text: str\n",
    "      - label: int\n",
    "    \"\"\"\n",
    "    def __init__(self, jsonl_path: str, img_dir: str, transform=None):\n",
    "        self.df = pd.read_json(jsonl_path, lines=True)\n",
    "        self.img_dir = Path(img_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        img_name = Path(str(row[\"img\"]).replace(\"\\\\\", \"/\")).name\n",
    "        img_path = self.img_dir / img_name\n",
    "\n",
    "        text = row[\"text\"]\n",
    "        label = int(row[\"label\"])\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, text, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    batch: list of (image_tensor, text_str, label_tensor)\n",
    "    returns batched tensors + list of texts\n",
    "    \"\"\"\n",
    "    images, texts, labels = zip(*batch)\n",
    "    images = torch.stack(images, dim=0)\n",
    "    labels = torch.stack(labels, dim=0)\n",
    "    return images, list(texts), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebbebf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model blocks\n",
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim: int = 512, freeze_backbone: bool = True):\n",
    "        super().__init__()\n",
    "        weights = ResNet50_Weights.DEFAULT\n",
    "        backbone = models.resnet50(weights=weights)\n",
    "        self.backbone = nn.Sequential(*list(backbone.children())[:-1])  # remove fc\n",
    "        self.projection = nn.Linear(2048, embedding_dim)\n",
    "\n",
    "        if freeze_backbone:\n",
    "            for p in self.backbone.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "    def forward(self, images: torch.Tensor) -> torch.Tensor:\n",
    "        # images: [B,3,224,224]\n",
    "        feats = self.backbone(images)           # [B,2048,1,1]\n",
    "        feats = feats.flatten(1)                # [B,2048]\n",
    "        emb = self.projection(feats)            # [B,512]\n",
    "        return emb\n",
    "\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim: int = 512, model_name: str = \"distilbert-base-uncased\", freeze_backbone: bool = True):\n",
    "        super().__init__()\n",
    "        self.bert = DistilBertModel.from_pretrained(model_name)\n",
    "        self.tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "        self.projection = nn.Linear(768, embedding_dim)\n",
    "\n",
    "        if freeze_backbone:\n",
    "            for p in self.bert.parameters():\n",
    "                p.requires_grad = False\n",
    "\n",
    "    def forward(self, texts, device: torch.device, max_length: int = 128) -> torch.Tensor:\n",
    "        enc = self.tokenizer(\n",
    "            texts,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "        )\n",
    "        enc = {k: v.to(device) for k, v in enc.items()}\n",
    "\n",
    "        out = self.bert(**enc)\n",
    "        cls = out.last_hidden_state[:, 0, :]    # [B,768]\n",
    "        emb = self.projection(cls)              # [B,512]\n",
    "        return emb\n",
    "\n",
    "\n",
    "class FusionClassifier(nn.Module):\n",
    "    def __init__(self, embedding_dim: int = 512, num_classes: int = 2):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(embedding_dim * 2, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, img_emb: torch.Tensor, txt_emb: torch.Tensor) -> torch.Tensor:\n",
    "        fused = torch.cat([img_emb, txt_emb], dim=1)  # [B,1024]\n",
    "        return self.classifier(fused)                 # [B,2]\n",
    "\n",
    "\n",
    "class MultimodalHatefulMemes(nn.Module):\n",
    "    def __init__(self, embedding_dim: int = 512, num_classes: int = 2):\n",
    "        super().__init__()\n",
    "        self.image_encoder = ImageEncoder(embedding_dim=embedding_dim, freeze_backbone=True)\n",
    "        self.text_encoder = TextEncoder(embedding_dim=embedding_dim, freeze_backbone=True)\n",
    "        self.fusion = FusionClassifier(embedding_dim=embedding_dim, num_classes=num_classes)\n",
    "\n",
    "    def forward(self, images, texts, device, max_length: int = 128):\n",
    "        img_emb = self.image_encoder(images)\n",
    "        txt_emb = self.text_encoder(texts, device=device, max_length=max_length)\n",
    "        logits = self.fusion(img_emb, txt_emb)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e24338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data prep\n",
    "def prepare_subset_data(train_jsonl_path: str, out_train: str, out_val: str, subset_size: int = 100, seed: int = 42):\n",
    "    df = pd.read_json(train_jsonl_path, lines=True)\n",
    "\n",
    "    subset, _ = train_test_split(\n",
    "        df,\n",
    "        train_size=subset_size,\n",
    "        stratify=df[\"label\"],\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    train_df, val_df = train_test_split(\n",
    "        subset,\n",
    "        test_size=0.2,\n",
    "        stratify=subset[\"label\"],\n",
    "        random_state=seed\n",
    "    )\n",
    "\n",
    "    Path(out_train).parent.mkdir(parents=True, exist_ok=True)\n",
    "    train_df.to_json(out_train, orient=\"records\", lines=True)\n",
    "    val_df.to_json(out_val, orient=\"records\", lines=True)\n",
    "\n",
    "    print(f\"✓ Subset created: {subset_size} samples\")\n",
    "    print(f\"  Train: {len(train_df)} | Val: {len(val_df)}\")\n",
    "    print(\"  Train distribution:\\n\", train_df[\"label\"].value_counts().to_string())\n",
    "    print(\"  Val distribution:\\n\", val_df[\"label\"].value_counts().to_string())\n",
    "\n",
    "\n",
    "def build_loaders(train_path: str, val_path: str, cfg: Config):\n",
    "    img_tf = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    train_ds = HatefulMemesDataset(train_path, str(img_dir), transform=img_tf)\n",
    "    val_ds = HatefulMemesDataset(val_path, str(img_dir), transform=img_tf)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=cfg.num_workers,\n",
    "        pin_memory=cfg.pin_memory,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=cfg.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=cfg.num_workers,\n",
    "        pin_memory=cfg.pin_memory,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0912b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Eval\n",
    "def train_one_epoch(model, loader, optimizer, criterion, device, cfg: Config):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, texts, labels in tqdm(loader, desc=\"Train\", leave=False):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        logits = model(images, texts, device=device, max_length=cfg.max_length)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    return total_loss / max(1, len(loader)), correct / max(1, total)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device, cfg: Config):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    all_probs = []\n",
    "\n",
    "    for images, texts, labels in tqdm(loader, desc=\"Eval\", leave=False):\n",
    "        images = images.to(device)\n",
    "\n",
    "        logits = model(images, texts, device=device, max_length=cfg.max_length)\n",
    "        probs = torch.softmax(logits, dim=1)[:, 1].cpu().numpy()\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "        all_probs.extend(probs.tolist())\n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_labels.extend(labels.numpy().tolist())\n",
    "\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    auc = roc_auc_score(all_labels, all_probs) if len(set(all_labels)) > 1 else float(\"nan\")\n",
    "    return acc, auc, np.array(all_labels), np.array(all_preds), np.array(all_probs)\n",
    "\n",
    "\n",
    "def save_confusion_matrix(y_true, y_pred, out_path: Path):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=[\"Not Hateful\", \"Hateful\"],\n",
    "        yticklabels=[\"Not Hateful\", \"Hateful\"],\n",
    "    )\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "667ceb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference helper\n",
    "@torch.no_grad()\n",
    "def predict_one(model, image_path: str, text: str, device, cfg: Config):\n",
    "    img_tf = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image = img_tf(image).unsqueeze(0).to(device)  # [1,3,224,224]\n",
    "\n",
    "    logits = model(image, [text], device=device, max_length=cfg.max_length)\n",
    "    probs = torch.softmax(logits, dim=1)[0]\n",
    "    pred = int(torch.argmax(probs).item())\n",
    "    conf = float(probs[pred].item())\n",
    "    return pred, conf, probs.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71ad0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main pipeline\n",
    "def run_pipeline():\n",
    "    cfg = Config()\n",
    "    seed_everything(cfg.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    train_subset_path = processed_dir / \"train_subset.jsonl\"\n",
    "    val_subset_path = processed_dir / \"val_subset.jsonl\"\n",
    "\n",
    "    # Step 1: subset\n",
    "    prepare_subset_data(\n",
    "        train_jsonl_path=str(train_jsonl),\n",
    "        out_train=str(train_subset_path),\n",
    "        out_val=str(val_subset_path),\n",
    "        subset_size=cfg.subset_size,\n",
    "        seed=cfg.seed\n",
    "    )\n",
    "\n",
    "    # Step 2: loaders\n",
    "    train_loader, val_loader = build_loaders(str(train_subset_path), str(val_subset_path), cfg)\n",
    "    print(f\"Train batches: {len(train_loader)} | Val batches: {len(val_loader)}\")\n",
    "\n",
    "    # Step 3: model\n",
    "    model = MultimodalHatefulMemes(embedding_dim=cfg.embedding_dim, num_classes=cfg.num_classes).to(device)\n",
    "\n",
    "    # Train only projections + fusion (backbones already frozen)\n",
    "    trainable_params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.Adam(trainable_params, lr=cfg.lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    print(f\"Trainable parameters: {sum(p.numel() for p in trainable_params):,}\")\n",
    "    print(f\"LR: {cfg.lr} | Epochs: {cfg.epochs}\")\n",
    "\n",
    "    best_acc = -1.0\n",
    "    best_path = models_dir / \"best_model.pth\"\n",
    "\n",
    "    # Step 4: training loop\n",
    "    for epoch in range(cfg.epochs):\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion, device, cfg)\n",
    "        val_acc, val_auc, y_true, y_pred, y_prob = evaluate(model, val_loader, device, cfg)\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}/{cfg.epochs}\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"  Val   Acc : {val_acc:.4f} | Val AUC : {val_auc:.4f}\")\n",
    "\n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"model_state\": model.state_dict(),\n",
    "                    \"epoch\": epoch,\n",
    "                    \"val_acc\": val_acc,\n",
    "                    \"val_auc\": val_auc,\n",
    "                    \"config\": cfg.__dict__,\n",
    "                },\n",
    "                best_path\n",
    "            )\n",
    "            print(\"  ✓ Saved best checkpoint\")\n",
    "\n",
    "    # Step 5: final report from last eval (and best acc printed)\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"FINAL VALIDATION RESULTS (last epoch eval)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"Best Val Accuracy: {best_acc:.4f}\")\n",
    "    print(f\"Last Val Accuracy: {val_acc:.4f}\")\n",
    "    print(f\"Last Val AUC     : {val_auc:.4f}\\n\")\n",
    "\n",
    "    print(classification_report(y_true, y_pred, target_names=[\"Not Hateful\", \"Hateful\"]))\n",
    "\n",
    "    cm_path = results_dir / \"confusion_matrix.png\"\n",
    "    save_confusion_matrix(y_true, y_pred, cm_path)\n",
    "    print(f\"✓ Confusion matrix saved to: {cm_path}\")\n",
    "\n",
    "    # Step 6: test one example (optional)\n",
    "    example_img = str(img_dir / \"02657.png\")\n",
    "    example_text = \"oh look someone's returning a broken sandwich maker to walmart\"\n",
    "\n",
    "    # load best model for inference\n",
    "    ckpt = torch.load(best_path, map_location=device)\n",
    "    model.load_state_dict(ckpt[\"model_state\"])\n",
    "    model.eval()\n",
    "\n",
    "    pred, conf, probs = predict_one(model, example_img, example_text, device, cfg)\n",
    "    print(\"\\nExample prediction:\")\n",
    "    print(f\"  pred={pred} ({'Hateful' if pred==1 else 'Not Hateful'}) | conf={conf:.4f}\")\n",
    "    print(f\"  probs: Not Hateful={probs[0]:.4f} | Hateful={probs[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1f09847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "✓ Subset created: 100 samples\n",
      "  Train: 80 | Val: 20\n",
      "  Train distribution:\n",
      " label\n",
      "0    51\n",
      "1    29\n",
      "  Val distribution:\n",
      " label\n",
      "0    13\n",
      "1     7\n",
      "Train batches: 10 | Val batches: 3\n",
      "Trainable parameters: 1,738,370\n",
      "LR: 0.001 | Epochs: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/10 [00:00<?, ?it/s]/Users/shrutisivakumar/Library/CloudStorage/OneDrive-Personal/College Stuff/Sem 6/Projects/NLP/Facebook-Hateful-Memes-Challenge-2020/hateful_memes_venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n",
      "  Train Loss: 0.6616 | Train Acc: 0.6250\n",
      "  Val   Acc : 0.6500 | Val AUC : 0.6923\n",
      "  ✓ Saved best checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/10 [00:00<?, ?it/s]/Users/shrutisivakumar/Library/CloudStorage/OneDrive-Personal/College Stuff/Sem 6/Projects/NLP/Facebook-Hateful-Memes-Challenge-2020/hateful_memes_venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10\n",
      "  Train Loss: 0.6749 | Train Acc: 0.5625\n",
      "  Val   Acc : 0.6500 | Val AUC : 0.7802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/10 [00:00<?, ?it/s]/Users/shrutisivakumar/Library/CloudStorage/OneDrive-Personal/College Stuff/Sem 6/Projects/NLP/Facebook-Hateful-Memes-Challenge-2020/hateful_memes_venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/10\n",
      "  Train Loss: 0.5479 | Train Acc: 0.7375\n",
      "  Val   Acc : 0.7500 | Val AUC : 0.8571\n",
      "  ✓ Saved best checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/10 [00:00<?, ?it/s]/Users/shrutisivakumar/Library/CloudStorage/OneDrive-Personal/College Stuff/Sem 6/Projects/NLP/Facebook-Hateful-Memes-Challenge-2020/hateful_memes_venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/10\n",
      "  Train Loss: 0.4170 | Train Acc: 0.8250\n",
      "  Val   Acc : 0.8000 | Val AUC : 0.8132\n",
      "  ✓ Saved best checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/10 [00:00<?, ?it/s]/Users/shrutisivakumar/Library/CloudStorage/OneDrive-Personal/College Stuff/Sem 6/Projects/NLP/Facebook-Hateful-Memes-Challenge-2020/hateful_memes_venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10\n",
      "  Train Loss: 0.3097 | Train Acc: 0.8750\n",
      "  Val   Acc : 0.6500 | Val AUC : 0.7033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/10 [00:00<?, ?it/s]/Users/shrutisivakumar/Library/CloudStorage/OneDrive-Personal/College Stuff/Sem 6/Projects/NLP/Facebook-Hateful-Memes-Challenge-2020/hateful_memes_venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10\n",
      "  Train Loss: 0.3061 | Train Acc: 0.8875\n",
      "  Val   Acc : 0.7000 | Val AUC : 0.8132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/10 [00:00<?, ?it/s]/Users/shrutisivakumar/Library/CloudStorage/OneDrive-Personal/College Stuff/Sem 6/Projects/NLP/Facebook-Hateful-Memes-Challenge-2020/hateful_memes_venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/10\n",
      "  Train Loss: 0.1503 | Train Acc: 0.9500\n",
      "  Val   Acc : 0.7000 | Val AUC : 0.7473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/10 [00:00<?, ?it/s]/Users/shrutisivakumar/Library/CloudStorage/OneDrive-Personal/College Stuff/Sem 6/Projects/NLP/Facebook-Hateful-Memes-Challenge-2020/hateful_memes_venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/10\n",
      "  Train Loss: 0.0726 | Train Acc: 0.9750\n",
      "  Val   Acc : 0.7000 | Val AUC : 0.7033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/10 [00:00<?, ?it/s]/Users/shrutisivakumar/Library/CloudStorage/OneDrive-Personal/College Stuff/Sem 6/Projects/NLP/Facebook-Hateful-Memes-Challenge-2020/hateful_memes_venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/10\n",
      "  Train Loss: 0.1456 | Train Acc: 0.9625\n",
      "  Val   Acc : 0.7000 | Val AUC : 0.8242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/10 [00:00<?, ?it/s]/Users/shrutisivakumar/Library/CloudStorage/OneDrive-Personal/College Stuff/Sem 6/Projects/NLP/Facebook-Hateful-Memes-Challenge-2020/hateful_memes_venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10\n",
      "  Train Loss: 0.0947 | Train Acc: 0.9500\n",
      "  Val   Acc : 0.6500 | Val AUC : 0.8462\n",
      "\n",
      "============================================================\n",
      "FINAL VALIDATION RESULTS (last epoch eval)\n",
      "============================================================\n",
      "Best Val Accuracy: 0.8000\n",
      "Last Val Accuracy: 0.6500\n",
      "Last Val AUC     : 0.8462\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Not Hateful       0.69      0.85      0.76        13\n",
      "     Hateful       0.50      0.29      0.36         7\n",
      "\n",
      "    accuracy                           0.65        20\n",
      "   macro avg       0.59      0.57      0.56        20\n",
      "weighted avg       0.62      0.65      0.62        20\n",
      "\n",
      "✓ Confusion matrix saved to: /Users/shrutisivakumar/Library/CloudStorage/OneDrive-Personal/College Stuff/Sem 6/Projects/NLP/Facebook-Hateful-Memes-Challenge-2020/results/confusion_matrix.png\n",
      "\n",
      "Example prediction:\n",
      "  pred=1 (Hateful) | conf=0.7447\n",
      "  probs: Not Hateful=0.2553 | Hateful=0.7447\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_pipeline()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hateful_memes_venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
